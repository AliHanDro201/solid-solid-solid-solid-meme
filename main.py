import eel
import os
import time
import logging

import elevenlabs as eleven
import webbrowser
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor
from utils.tts import stop_audio as tts_stop_audio
from core.gpt_service import generate_gpt_response, handle_user_input
from core.config import SECOND_OPENAI_API_KEY, ELEVENLABS_API_KEY
import tempfile

import base64, tempfile
from openai import OpenAI            # ¬†v1.x   ‚Üê pip install --upgrade openai
client = OpenAI(api_key=os.getenv("SECOND_OPENAI_API_KEY"))
# ‚úÖ –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler("app.log", encoding="utf-8")
    ]
)
logger = logging.getLogger(__name__)

# ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv(dotenv_path=".env")
OpenAI.api_key = SECOND_OPENAI_API_KEY
if ELEVENLABS_API_KEY:
    eleven.set_api_key(ELEVENLABS_API_KEY)

# ‚úÖ –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
executor = ThreadPoolExecutor(max_workers=1)
isRecognizing = False
# ‚úÖ –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
@eel.expose
def transcribe_audio(b64_audio: str) -> str:
    """
    JS –æ—Ç–¥–∞—ë—Ç base‚Äë64 —Å—Ç—Ä–æ–∫—É (webm).
    –î–µ–∫–æ–¥–∏—Ä—É–µ–º ‚Üí –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª ‚Üí Whisper¬†v3 (¬´whisper‚Äë1¬ª).
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç.
    """
    data = base64.b64decode(b64_audio)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as tmp:
        tmp.write(data)
        tmp_path = tmp.name           # –Ω—É–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –∑–∞–Ω–æ–≤–æ –¥–ª—è —á—Ç–µ–Ω–∏—è

    rsp = client.audio.transcriptions.create(
        model="whisper-1",
        file=open(tmp_path, "rb"),
        response_format="text"
    )
    return rsp  # —ç—Ç–æ —É–∂–µ plain‚Äëtext

# ‚úÖ Eel –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
@eel.expose
def stop_audio_ui():
    logger.info("–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞—É–¥–∏–æ –ø–æ –∑–∞–ø—Ä–æ—Å—É –∏–∑ UI")
    return tts_stop_audio()

@eel.expose
def process_input(text: str) -> str:
    response = handle_user_input(text)
    logger.info(f"–û—Ç–≤–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π process_input: {response}")
    return response

# ‚úÖ –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ Eel

def main():
    eel.init('ui')

    eel.start('main.html')
    # üïê –ü–∞—É–∑–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    time.sleep(2)

    try:
        eel.muteAssistant()
        logger.info("üéôÔ∏è muteAssistant –≤—ã–∑–≤–∞–Ω –∏–∑ Python ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –º–æ–ª—á–∏—Ç")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–∑–≤–∞—Ç—å muteAssistant: {e}")
    webbrowser.open("http://localhost:8000/main.html")
    # üîÅ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logger.info("‚õî –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")


if __name__ == "__main__":
    main()
